# IT-Specialist-DATA-ANALYTICS-Part-3

Welcome to this Python learning repository!

This repository is designed to make learning Data Analist for students easy and enjoyable. Here, you'll find various learning materials, including:

[Basic Of Visualization and communication]
[4 reasons use chart]
[Data Visualization using Python]
[CRISP-DM]
[Describe Data Privacy Laws and Best Practices]


# Basic Of Visualization and communication
Data visualization is the graphical representation of information and data. By using visual elements like charts, graphs, and maps, data visualization tools provide an accessible way to see and understand trends, outliers, and patterns in data. Additionally, it provides an excellent way for employees or business owners to present data to non-technical audiences without confusion.

## Chart
A chart is a graphic representation of data that transforms the data into visual components. For example, a pie chart uses slices of a circle and color coding to distinguish between categories of data.

# 4 reasons use chart
## Comparison
* **Bar chart vertical ( Compare among categories Few category)**
A bar graph, as you might guess, uses bars to convey data. The longer the bar, the greater the value. Say a bar graph shows sales per store for the past quarter.

* **Bar chart horizontal (Has long item label)**
A horizontal bar chart is a graph in the form of rectangular bars. It's a data visualization technique. The length of these bars is proportional to the values they represent. The bar chart title indicates which data is represented.

* **Line Chart (Compare over time)**
Line graphs typically are used to show changes or trends in continuous data over a period of time, with a line connecting the dots that represent the different values. For instance, in a line chart showing a company's stock price over the past week, a line would connect the dots that visualize the change in price each day.

## Composition
## Relationship
## Spatial

# Data Visualization using Python
## Matplotlib
Matplotlib is a comprehensive Python library used for both static and interactive data visualization. Visualizations produced by Matplotlib Python can be presented in either 2D or 3D.

## Seaborn
Seaborn is a library for creating graphs and statistics using Python. This library is built based on the existing Matplotlib library. Then integrated with the data structure in Pandas.

# CRISP-DM
CRISP-DM stands for Cross-Industry Standard Process for Data Mining. It is a cyclical process that provides a structured approach to planning, organizing, and implementing a data mining project. The process consists of six major phases:
## business understanding
It has a quite vital part. Business understanding requires knowledge of the business objects, how to build or obtain data, and how to match modeling goals to business goals; so that the best model can be built. Activities carried out include: define business objectives, assessing the current scenario, setting data mining targets, and creating a project plan. 
## data understanding
Data understanding provides the analytical foundation for a study by creating a summary and identifying potential problems in the data. It must also be carried out carefully and not in a rush, such as in data visualization, where sometimes the insight is very difficult to obtain when connected to the summary data. If there are problems at this step that have not been answered, it will interfere with the modeling step.
## data preparation
The data is rarely clean. Data preparation focuses on cleaning and translating raw data into a modelable format. It includes: selecting data, cleaning data, constructing data (feature engineering), integrating data, and formatting data.
## modeling
With clean data at hand, numerous modeling strategies are used. Each approach may require specialized data formats, so it is not uncommon to return to the data preparation phase. Key activities include: selecting modeling techniques, designing tests, building the model, and evaluating the model.
## evaluation
Evaluation is used to analyze the outcomes of data mining generated during the preceding stage of the modeling process. This is done on the model used in the previous step, with the goal of ensuring that the model determined is consistent with the objectives set in the first step.
## deployment
The model is finally deployed in a real-world situation. This might be as easy as creating a report or as complicated as establishing a repeatable data mining process. The key activities include planning deployment, monitoring and maintenance, reviewing the project, and completing the project.

# Describe Data Privacy Laws and Best Practices
## GDPR
## FERPA
## HIPAA
## IRB
## PCI DSS
